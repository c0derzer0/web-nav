[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for andrew ng, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "2"}, {"role": "user", "content": "Action result: \ud83d\udd17  Navigated to https://www.google.com"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "3"}, {"role": "user", "content": "Action result: \u2328\ufe0f  Input andrew ng into index 6"}, {"role": "user", "content": "Action result: Something new appeared after action 1 / 2"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "4"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 21: "}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: https://www.google.com/search?q=andrew+ng&sca_esv=0e1aa4f886ac3be0&source=hp&ei=O-wCaNnPDYSviLMP-tDZgQ8&iflsig=ACkRmUkAAAAAaAL6S_rOz8GWkqS57uvCZ38MjWSCr1Ik&ved=0ahUKEwiZ2erI6eKMAxWEF2IAHXpoNvAQ4dUDCA8&oq=andrew+ng&gs_lp=Egdnd3Mtd2l6IglhbmRyZXcgbmcyCBAuGIAEGLEDMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEC4YgAQyBRAAGIAESOsqUABYAHAAeACQAQCYATugATuqAQExuAEMyAEA-AEBmAIBoAJAmAMAkgcBMaAH-giyBwExuAdA&sclient=gws-wiz&sei=ROwCaP6iEPCf5NoPztjiwAg\nAvailable tabs:\n[TabInfo(page_id=0, url='https://www.google.com/search?q=andrew+ng&sca_esv=0e1aa4f886ac3be0&source=hp&ei=O-wCaNnPDYSviLMP-tDZgQ8&iflsig=ACkRmUkAAAAAaAL6S_rOz8GWkqS57uvCZ38MjWSCr1Ik&ved=0ahUKEwiZ2erI6eKMAxWEF2IAHXpoNvAQ4dUDCA8&oq=andrew+ng&gs_lp=Egdnd3Mtd2l6IglhbmRyZXcgbmcyCBAuGIAEGLEDMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIFEC4YgAQyBRAAGIAESOsqUABYAHAAeACQAQCYATugATuqAQExuAEMyAEA-AEBmAIBoAJAmAMAkgcBMaAH-giyBwExuAdA&sclient=gws-wiz&sei=ROwCaP6iEPCf5NoPztjiwAg', title='andrew ng - Google Search')]\nInteractive elements from top layer of the current page inside the viewport:\n[Start of page]\nAccessibility Links\nSkip to main content\nAccessibility help\nAccessibility feedback\n[0]<a Go to Google Home/>\n[1]<textarea ;Search;q;combobox;false>andrew ng/>\n[2]<div  Clear;button/>\n[3]<div Search by voice;button/>\n[4]<div button;Search by image/>\n[5]<button Search;submit/>\n[6]<div Settings;button>Quick Settings/>\n[7]<a Google apps;button;false/>\n[8]<a Sign in/>\nFilters and Topics\n[9]<a link>All/>\n[10]<a link>Images/>\n[11]<a link>News/>\n[12]<a link>Videos/>\n[13]<a link>Short videos/>\n[14]<a link>Shopping/>\n[15]<a link>Forums/>\n[16]<div button;false>More/>\n[17]<div button;false>Tools/>\nAndrew Ng\nBritish-American computer scientist\n[18]<div button;false/>\nSearch Results\n[19]<img />\nSteve Jennings\n[20]<img />\n[21]<img />\n[22]<a />\n[23]<a />\nAndrewYNg\nX\nI\u2019ve noticed that many GenAI application projects put in automated evaluations (evals) of the system\u2019s output probably later \u2014 and rely on humans to judge outputs longer \u2014 than they should. This is because building evals is viewed as a massive investment (say, creating 100 or 1,000 examples, and designing and validating metrics) and there\u2019s never a convenient moment to put in that up-front cost. Instead, I ...\n1 day ago\n[24]<a Age\n49 years\nApr 18, 1976/>\n[25]<div button;false>Education/>\nUC Berkeley College of Engineering\n,\nMassachusetts Institute of Technology\n,\nCarnegie Mellon University\n,\nRaffles Institution\n[26]<img />\n[27]<img />\n+2\n[28]<a />\nLinkedIn\nAndrew Ng - Founder - DeepLearning.AI - LinkedIn\nAndrew Ng is an influencer. Founder of DeepLearning.AI; Managing General Partner of AI Fund; Exec Chairman of Landing AI.\nMain Results\n[29]<a Andrew Ng: Home\nandrewng.org\nhttps://www.andrewng.org/>\n[30]<div button;About this result/>\n[31]<a />\n[32]<img />\nDr. Andrew Ng is a\nglobally recognized leader in AI\n(Artificial Intelligence). He is Founder & CEO of DeepLearning.AI, Founder & CEO of Landing AI,\u00a0...\n[33]<a Courses/>\n[34]<a About/>\n[35]<a Publications/>\n[36]<a Projects/>\n[37]<a Andrew Ng\nWikipedia\nhttps://en.wikipedia.org\n\u203a wiki \u203a Andrew_Ng/>\n[38]<img />\n[39]<div button;About this result/>\n[40]<a />\n[41]<img />\nAndrew Yan-Tak Ng is\na British-American computer scientist and technology entrepreneur\nfocusing on machine learning and artificial intelligence (AI). Ng was\u00a0...\nPeople also ask\n[42]<div button;About this result/>\n[43]<div button;false>Why is Andrew Ng so famous?/>\n[44]<div button;false>How much does Andrew Ng earn?/>\n[45]<div button;false>Is Andrew Ng a good teacher?/>\n[46]<div button;false>How do you pronounce Andrew Ng?/>\n[47]<div button>Feedback/>\n[48]<a Andrew Ng - Founder - DeepLearning.AI\nLinkedIn\u00a0\u00b7\u00a0Andrew Ng\n2M+ followers/>\n[49]<img />\n[50]<div button;About this result/>\nAndrew Ng is an influencer.\nFounder of DeepLearning.AI\n; Managing General Partner of AI Fund; Exec Chairman of Landing AI.\nWhat people are saying\n[51]<div button;About this result/>\n[52]<a New Short Course: Building AI Browser Agents! Learn how to build AI agents that interact with and take actions on websites in this course, created in partnership with AGI Inc and taught by Div Garg @DivGarg_ and Naman Garg, Co-founders of AGI Inc. AI bro/>\n[53]<img />\n[54]<a />\n[55]<img />\n[56]<img />\n[57]<a link/>\nStanford\u2019s Machine Learning - by Andrew Ng\n\nA complete lecture notes of 227 pages. Available Free.\n[58]<a Stanford professor and former Google Brain scientist Andrew Ng said that \"lazy prompting\" can be an efficient way to use AI \u2014 in some scenarios. Lazy prompting entails giving minimal context to large language models. Read more: https://www.businessinside/>\n[59]<img />\n[60]<a 14:42\nCharting the new Coursera... Andrew Ng and Greg Hart | ASU+GSV Summit 2025/>\n[61]<img />\n[62]<a Completed Andrew Ng Machine Learning Specialization course. Where to go next?\nTop comment \u00b7\nOne way is to take projects off of kaggle. Improve the pipelines with stronger software engineering rigor and documentation. Then move to learning MLOps, then deep learning. Most importantly understand the audience. Often times I have to start with a simple distance algorithm or decision tree to get the stakeholders to understand the output and workflow. After that I evaluate more advanced models. Really reproduciblilty and accurate data is most vital. I\u2019ve made an ass of myself demoing code with bugs or bad data/>\n[63]<a />\n[64]<img />\n[65]<a />\n[66]<img />\n[67]<img />\n[68]<img />\n[69]<img />\n[70]<a link/>\nMachine learning and data science follow different playbooks\u2014but both are transforming how organizations operate.\n\nIn Week 2 of the AI for Everyone course, Andrew Ng shows you what it takes to build AI and data projects: from collecting data to training models to deploying them\n[71]<a />\n[72]<img />\n[73]<a link/>\nOne man predicted EVERY AI breakthrough of the past decade.\n\nBecause of him:\n\n\u2022 Your phone understands speech\n\u2022 Your car can drive itself\n\u2022 AI can detect cancer\n\nNow, he warns AI will make the internet unrecognizable within 2 years.\n\nHere's what Andrew Ng foresees:\nComplementary Results\nOverview\nDescription\nAndrew Yan-Tak Ng is a British-American computer scientist and technology entrepreneur focusing on machine learning and artificial intelligence.\n[74]<a Wikipedia/>\nBorn\n:\n1976 (age 49\u00a0years),\n[75]<a London, United Kingdom/>\nEducation\n:\n[76]<a UC Berkeley College of Engineering/>\n(2002)\n\u00b7\n[77]<a See more/>\nSpouse\n:\n[78]<a Carol E. Reiley/>\n(m. 2014)\nChildren\n:\n2\nKnown for\n:\nArtificial intelligence,\n[79]<a deep learning/>\n, MOOC, education technology\nMother\n:\n[80]<a Tisa Ho/>\nDoctoral advisor\n:\n[81]<a Michael I. Jordan/>\n[82]<div button>Feedback/>\nProfiles\nLinkedIn\nX (Twitter)\nYouTube\nFacebook\nPeople also search for\n[83]<a />\n[84]<img />\nDaphne Koller\n[85]<a />\n[86]<img />\nCarol E. Reiley\n[87]<a />\n[88]<img />\nNova Ng\n[89]<a />\n[90]<img />\nAshutosh Saxena\n[91]<a See more/>\n... 3525 pixels below - scroll or extract content to see more ...\nCurrent step: 4/100Current date and time: 2025-04-18 20:20\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - The search for 'andrew ng' was submitted and results are displayed. Needed to find Google Scholar next.\", \"memory\": \"Googled for 'andrew ng', results are visible. 3/6 completed. Need to locate and navigate to Andrew Ng's Google Scholar page to proceed.\", \"next_goal\": \"Look on the page or scroll if needed to find and click on the link to Andrew Ng's Google Scholar profile.\"}, \"action\": [{\"extract_content\": {\"goal\": \"Find and extract the visible links relating to Andrew Ng's Google Scholar profile.\"}}]}}"}]
[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for andrew ng, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "2"}, {"role": "user", "content": "Action result: \ud83d\udd17  Navigated to https://www.google.com"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "3"}, {"role": "user", "content": "Action result: \u2328\ufe0f  Input andrew ng into index 6"}, {"role": "user", "content": "Action result: Something new appeared after action 1 / 2"}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: https://www.google.com/\nAvailable tabs:\n[TabInfo(page_id=0, url='https://www.google.com/', title='Google')]\nInteractive elements from top layer of the current page inside the viewport:\n[Start of page]\n[0]<a About/>\n[1]<a Store/>\n[2]<a Gmail >Gmail/>\n[3]<a Search for Images >Images/>\n[4]<a Google apps;button;false/>\n[5]<a Sign in/>\n[6]<textarea Search;q;true;combobox/>\n[7]<div  Clear;button/>\n[8]<div Search by voice;button/>\n[9]<div button;Search by image/>\n[10]<ul listbox>See more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete\nSee more\nDelete/>\n[11]<div andrew ng;option>Andrew Ng\nBritish-American computer scientist/>\n[12]<div andrew ng machine learning;option>andrew ng\nmachine learning/>\n[13]<div option;andrew nguyen>andrew ng\nuyen/>\n[14]<div andrew ng net worth;option>andrew ng\nnet worth/>\n[15]<div option;andrew ng deep learning>andrew ng\ndeep learning/>\n[16]<div andrew ng ai course;option>andrew ng\nai course/>\n[17]<div option;andrew ng course>andrew ng\ncourse/>\n[18]<div andrew nguyen paper;option>andrew ng\nuyen paper/>\n[19]<div andrew ngai;option>Andrew Ngai/>\n[20]<div andrew ng machine learning coursera;option>andrew ng\nmachine learning coursera/>\n[21]<input Google Search;submit;button;btnK/>\n[22]<input I'm Feeling Lucky;submit;btnI/>\n[23]<div button>Report inappropriate predictions/>\nToday is World Heritage Day:\nExplore the most iconic places on Earth\n[24]<a Advertising/>\n[25]<a Business/>\n[26]<a How Search works/>\n[27]<a Our third decade of climate action: join us/>\n[28]<img />\n[29]<a Privacy/>\n[30]<a Terms/>\n[31]<div button;false>Settings/>\n[32]<img />\nSign in to Google\nGet the most from your Google account\n[33]<div button>Stay signed out/>\n[34]<div button>Sign in/>\n[End of page]\nCurrent step: 3/100Current date and time: 2025-04-18 20:20\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - Input 'andrew ng' into the Google search bar, suggestions appeared as expected.\", \"memory\": \"Step 3: 'andrew ng' entered into search bar. Suggestions list appeared. 2/6 major steps completed. Next: Submit the search to view full Google results page.\", \"next_goal\": \"Submit the search for 'andrew ng' by clicking the 'Google Search' button.\"}, \"action\": [{\"click_element\": {\"index\": 21}}]}}"}]
[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for andrew ng, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "2"}, {"role": "user", "content": "Action result: \ud83d\udd17  Navigated to https://www.google.com"}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: https://www.google.com/\nAvailable tabs:\n[TabInfo(page_id=0, url='https://www.google.com/', title='Google')]\nInteractive elements from top layer of the current page inside the viewport:\n[Start of page]\n[0]<a About/>\n[1]<a Store/>\n[2]<a Gmail >Gmail/>\n[3]<a Search for Images >Images/>\n[4]<a Google apps;button;false/>\n[5]<a Sign in/>\n[6]<textarea Search;q;combobox;false/>\n[7]<div Search by voice;button/>\n[8]<div button;Search by image/>\n[9]<input Google Search;submit;button;btnK/>\n[10]<input I'm Feeling Lucky;submit;button;btnI/>\nToday is World Heritage Day:\n[11]<a link>Explore the most iconic places on Earth/>\n[12]<a Advertising/>\n[13]<a Business/>\n[14]<a How Search works/>\n[15]<a Our third decade of climate action: join us/>\n[16]<img />\n[17]<a Privacy/>\n[18]<a Terms/>\n[19]<div button;false>Settings/>\n[20]<img />\nSign in to Google\nGet the most from your Google account\n[21]<div button>Stay signed out/>\n[22]<div button>Sign in/>\n[End of page]\nCurrent step: 2/100Current date and time: 2025-04-18 20:20\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - Navigated to google.com. The search bar is available.\", \"memory\": \"Step 2 complete. On Google homepage, ready to search. 1/6 major actions completed. Next: Search for 'andrew ng'.\", \"next_goal\": \"Type 'andrew ng' in the search bar and submit the search.\"}, \"action\": [{\"input_text\": {\"index\": 6, \"text\": \"andrew ng\"}}, {\"click_element\": {\"index\": 9}}]}}"}]
[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for andrew ng, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: about:blank\nAvailable tabs:\n[TabInfo(page_id=0, url='about:blank', title='')]\nInteractive elements from top layer of the current page inside the viewport:\nempty page\nCurrent step: 1/100Current date and time: 2025-04-18 20:20\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - The browser opened to a blank page as expected.\", \"memory\": \"Step 1 of task started. Browser is open at about:blank. Need to search Google for 'andrew ng'.\", \"next_goal\": \"Go to google.com to begin the search for 'andrew ng'.\"}, \"action\": [{\"go_to_url\": {\"url\": \"https://www.google.com\"}}]}}"}]
[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for geoffrey hinton, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "2"}, {"role": "user", "content": "Action result: \ud83d\udd0d  Searched for \"Geoffrey Hinton\" in Google"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "3"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 32: Geoffrey Hinton"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "4"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 62: Year"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "5"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 55: Homepage"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "6"}, {"role": "user", "content": "Action result: \ud83d\udcc4  Extracted from page\n: ```json\n{\n  \"person\": \"Geoffrey Hinton\",\n  \"extraction_goal\": \"Summarize Geoffrey Hinton's research interests, including any stated areas, focus, or major contributions.\",\n  \"research_interests\": [\n    \"Deep Learning\",\n    \"Neural Networks\",\n    \"Machine Learning\",\n    \"Artificial Intelligence\"\n  ],\n  \"focus_areas_and_themes\": [\n    {\n      \"area\": \"Deep Belief Networks\",\n      \"details\": \"Co-invented Deep Belief Nets; Developed fast learning algorithms for these networks.\"\n    },\n    {\n      \"area\": \"Backpropagation and Learning Algorithms\",\n      \"details\": \"Exploration of biologically plausible alternatives to backpropagation in neural networks (e.g., Forward-Forward Algorithm).\"\n    },\n    {\n      \"area\": \"Representation Learning\",\n      \"details\": \"Work on methods for reducing the dimensionality of data using neural networks (e.g., deep autoencoders).\"\n    },\n    {\n      \"area\": \"Generative Models\",\n      \"details\": \"Development of neural network models capable of generating and recognizing complex data such as images (e.g., movies of generating digits).\"\n    },\n    {\n      \"area\": \"Interpretable Machine Learning\",\n      \"details\": \"Development of neural additive models for interpretable machine learning with neural networks.\"\n    },\n    {\n      \"area\": \"Unsupervised and Self-supervised Learning\",\n      \"details\": \"Work on algorithms where learning can occur with minimal supervision, as in Deep Belief Nets and other recent approaches.\"\n    },\n    {\n      \"area\": \"Neuro-inspired Computation\",\n      \"details\": \"Investigation of mechanisms inspired by the brain, including how backpropagation-like processes might be realized in biological neural systems.\"\n    },\n    {\n      \"area\": \"Data Visualization and Embeddings\",\n      \"details\": \"Development and use of t-SNE for visualizing high-dimensional data (e.g., word vectors).\"\n    },\n    {\n      \"area\": \"Diffusion Models & Discrete Data Generation\",\n      \"details\": \"Recent work on generating discrete data using diffusion models with self-conditioning.\"\n    },\n    {\n      \"area\": \"Vision and Sequence Interfaces\",\n      \"details\": \"Unified sequence interface for vision tasks; panoptic segmentation of images and videos.\"\n    }\n  ],\n  \"major_contributions\": [\n    {\n      \"title\": \"Deep Belief Networks\",\n      \"citation\": \"Hinton, G. E., Osindero, S. and Teh, Y. (2006) A fast learning algorithm for deep belief nets. Neural Computation, 18, pp 1527-1554.\"\n    },\n    {\n      \"title\": \"Dimensionality Reduction with Neural Networks\",\n      \"citation\": \"Hinton, G. E. and Salakhutdinov, R. R. (2006) Reducing the dimensionality of data with neural networks. Science, Vol. 313. no. 5786, pp. 504 - 507.\"\n    },\n    {\n      \"title\": \"Foundational Review of Deep Learning\",\n      \"citation\": \"LeCun, Y., Bengio, Y. and Hinton, G. E. (2015) Deep Learning. Nature, Vol. 521, pp 436-444.\"\n    },\n    {\n      \"title\": \"Forward-Forward Algorithm\",\n      \"citation\": \"Hinton, G. E. (2022) The Forward-Forward Algorithm: Some Preliminary Investigations arXiv:2212.13345.\"\n    },\n    {\n      \"title\": \"Interpretable Neural Additive Models\",\n      \"citation\": \"Agarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B., Caruana, R., & Hinton, G. E. (2021) Neural additive models: Interpretable machine learning with neural nets. NeurIPS.\"\n    },\n    {\n      \"title\": \"t-SNE Data Visualization\",\n      \"citation\": \"Software and applications for visualizing high-dimensional data, notably for word embeddings.\"\n    }\n  ],\n  \"teaching_and_impact\": [\n    \"Produced extensive tutorials and lecture series on deep learning, neural networks, and related topics (e.g., Coursera, NIPS, CIFAR Summer Schools).\",\n    \"Mentored and supervised many prominent researchers and students in AI.\",\n    \"Has contributed both foundational algorithms and practical software tools utilized widely in machine learning community.\"\n  ],\n  \"recent_topics\": [\n    \"Forward-Forward Algorithm\",\n    \"Diffusion models with self-conditioning\",\n    \"Scaling forward gradient with local losses\",\n    \"Unified sequence interfaces for vision tasks\",\n    \"Panoptic segmentation of images and videos\",\n    \"Gaussian-Bernoulli Restricted Boltzmann Machines\"\n  ],\n  \"summary\": \"Geoffrey Hinton is a pioneering researcher in the field of machine learning and artificial intelligence, with major contributions to deep learning, neural networks, representation learning, and biologically plausible learning algorithms. His work spans foundational theoretical algorithms, innovative practical models (such as Deep Belief Nets and deep autoencoders), interpretable AI, and data visualization. He continues to explore new learning paradigms including the Forward-Forward algorithm, and his research has had broad impact on both academia and industry.\"\n}\n```\n"}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: https://www.cs.toronto.edu/~hinton/\nAvailable tabs:\n[TabInfo(page_id=0, url='https://www.cs.toronto.edu/~hinton/', title='Home Page of Geoffrey Hinton')]\nInteractive elements from top layer of the current page inside the viewport:\n[Start of page]\nBIOGRAPHICAL INFORMATION\n......Curriculum Vitae\n[0]<a .pdf/>\n......\n[1]<a Biographical sketch/>\n......\n[2]<a Brief Bio/>\n......\n[3]<a Photographs/>\nPUBLICATIONS\n......\n[4]<a Publications by year/>\n......\n[5]<a Slides of public talks/>\nMEDIA INTERVIEWS\n....\n[6]<a CBS 60 Minutes, Sept 2023/>\n....\n[7]<a Interview at Collision Conference, Toronto, June 2023/>\n....\n[8]<a CNN Amanpour and Company, May 2023/>\n....\n[9]<a PBS, May 2023/>\n....\n[10]<a BBC News, May 2023/>\n....\n[11]<a CNN Jake Tapper, May 2023/>\n....\n[12]<a CBC The National, May 2023/>\n....\n[13]<a CBS Morning News, March 2023/>\n....\n[14]<a Interview on CBC radio \"The Current\", May 5 2015/>\nVIDEO LECTURES\n....\n[15]<a YouTube (Feb 2024)\nThe Romanes Lecture (40mins)/>\n....\n[16]<a YouTube (Dec\n2023)\nThe Arthur Miller Lecture on Science and Ethics (1.13hr)/>\n....\n[17]<a YouTube (May 2023)\nTwo Paths to Intlligence (1hr)/>\n....\n[18]<a YouTube (2012)\nBrains, Sex and Machine Learning (1hr)/>\n....\n[19]<a YouTube (2007)\nThe Next Generation of Neural Networks (1hr)/>\n....\n[20]<a YouTube (2010)\nRecent Developments in Deep Learning (1hr)/>\nTUTORIALS\n....\n[21]<a Tutorial (2009)\nDeep Belief Nets (3hrs)/>\n[22]<a ppt/>\n[23]<a pdf/>\n[24]<a readings/>\n....\n[25]<a Workshop Talk (2007)\nHow to do backpropagation in a brain (20mins)/>\n[26]<a ppt2007/>\n[27]<a pdf2007/>\n[28]<a ppt2014/>\n[29]<a pdf2014/>\n2012 COURSERA COURSE LECTURES:\nNeural Networks for Machine Learning\n....\n[30]<a Lectures/>\n(.mp4)\n....\n[31]<a Lecture Slides/>\n(.pptx or .pdf))\nOLD UNIVERSITY OF TORONTO COURSES\n....\n[32]<a csc321 Spring\n2013/>\n(undergrad)\n....\n[33]<a csc2535 Spring 2013/>\n(graduate)\nOLD TUTORIAL SLIDES\n....\n[34]<a 2011 NIPS workshop talk pdf/>\n[35]<a ppt/>\n........\n[36]<a paper\non Transforming Autoencoders/>\n....\n[37]<a 2007 NIPS tutorial html/>\n[38]<a ppt/>\n[39]<a ps/>\n[40]<a pdf/>\n........\n[41]<a Readings:\n2007 NIPS tutorial/>\n....\n[42]<a CIFAR Summer School 2007/>\n....\n[43]<a CIAR Summer School 2006/>\n....\n[44]<a CIFAR Summer School 2005/>\n....\n[45]<a List of Past Tutorials/>\nMOVIES\n....\n[46]<a generating digits/>\n....\n[47]<a speaking\nwith a glove (Sidney Fels)/>\nMATLAB CODE\n....\n[48]<a Matlab for Science paper/>\n....\n[49]<a t-SNE software/>\n....\n[50]<a trajectory from motor program/>\n....\n[51]<a ink from trajectory/>\n....\n[52]<a introduction to python/>\nSUPERVISION\n....\n[53]<a Current PhD and Master's Students/>\n....\n[54]<a Former PhD Students/>\n....\n[55]<a Former Master's Students/>\n....\n[56]<a PostDocs/>\nMACHINE LEARNING AT TORONTO\n....\n[57]<a learning.cs.toronto.edu/>\nHOME PAGE (top level)\n....\n[58]<a www.cs.toronto.edu/~hinton/>\nGeoffrey E. Hinton\nDepartment of Computer Science\nemail\n: geoffrey [dot] hinton [at]\ngmail [dot] com\n[59]<a University of Toronto/>\nvoice\n: send email\n6 King's College Rd.\nfax\n: scan and send email\nToronto, Ontario\nInformation for prospective students, postdocs and visitors:\nI will not be taking any more students, postdocs or visitors.\nBasic papers on deep learning\nLeCun, Y., Bengio, Y. and Hinton, G. E. (2015)\nDeep Learning\nNature, Vol. 521, pp 436-444.\n[\n[60]<a pdf/>\n]\nHinton, G. E., Osindero, S. and Teh, Y. (2006)\nA fast learning algorithm for deep belief nets.\nNeural Computation,\n18\n, pp 1527-1554. \n[\n[61]<a pdf/>\n]\n[62]<a Movies of the neural network generating and recognizing digits/>\nHinton, G. E. and Salakhutdinov, R. R. (2006)\nReducing the dimensionality of data with neural networks.\nScience, Vol. 313. no. 5786, pp. 504 - 507, 28 July 2006.\n[\n[63]<a full paper/>\n]\n[\n[64]<a supporting online material (pdf)/>\n]\n[\n[65]<a Matlab code/>\n]\nRecent Papers\nHinton, G. E. (2022)\nThe Forward-Forward Algorithm: Some Preliminary\nInvestigations\narXiv:2212.13345\n[\n[66]<a pdf of final version/>\n]\n[\n[67]<a ffcode.zip matlab code for the supervised version of FF\nwith the first 10 pixels being the labels/>\n]\n[\n[68]<a load mnistdata.mat in matlab to create the data/>\n]\n[\n[69]<a README.txt explains what to do to run\nFF/>\n}\nSindy Loewe's translation to python code is available at\nhttps://github.com/loeweX/Forward-Forward\nChen, T., Zhang, R., & Hinton, G. (2022)\nAnalog bits: Generating discrete data using diffusion models with\nself-conditioning\narXiv preprint arXiv:2208.04202\n[\n[70]<a pdf/>\n]\nRen, M., Kornblith, S., Liao, R., & Hinton, G. (2022)\nScaling Forward Gradient With Local Losses\narXiv preprint arXiv:2210.03310\n[\n[71]<a pdf/>\n]\nChen, T., Saxena, S., Li, L., Lin, T. Y., Fleet, D. J., & Hinton, G. (2022)\nA unified sequence interface for vision tasks\narXiv preprint arXiv:2206.07669\n[\n[72]<a pdf/>\n]\nChen, T., Li, L., Saxena, S., Hinton, G., & Fleet, D. J.(2022)\nA generalist framework for panoptic segmentation of images and\nvideos\narXiv preprint arXiv:2210.06366\n[\n[73]<a pdf/>\n]\nLiao, R., Kornblith, S., Ren, M., Fleet, D. J., & Hinton, G. (2022)\nGaussian-Bernoulli RBMs Without Tears\narXiv preprint arXiv:2210.10318\n[\n[74]<a pdf/>\n]\nCulp, L., Sabour, S., & Hinton, G. E. (2022)\nTesting GLOM's ability to infer wholes from ambiguous parts\narXiv preprint arXiv: 2211.16564\n[\n[75]<a pdf/>\n]\nAgarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B.,\nCaruana, R., & Hinton, G. E. (2021)\nNeural additive models:Interpretable machine learning with neural nets\nAdvances in Neural Information Processing Systems, 34, 4699-4711.\n[\n[76]<a pdf/>\n]\nBengio, Y., Lecun, Y., & Hinton, G. (2021)\nDeep learning for AI\nCommunications of the ACM, 64(7), 58-65.\n[\n[77]<a pdf/>\n]\n[78]<a 2021 commencement address at IIT Mumbai/>\n[79]<a Joseph Turian's map of 2500 English words produced by using t-SNE on\n the word feature vectors learned by Collobert & Weston, ICML 2008/>\n[80]<a Doing analogies by using vector algebra on word embeddings (in 2008)/>\n[81]<a My old favorite Gary Marcus quote/>\n[82]<a GPT-4 corrects Gary Marcus/>\nMy new favorite Gary Marcus quote\n\"It gloms on to different clusters of text. That is all.\"\n[83]<a A new concept of healing from the people who design unimprovised\n   explosive devices/>\n... 511 pixels below - scroll or extract content to see more ...\nCurrent step: 6/100Current date and time: 2025-04-18 20:19\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - Extracted comprehensive information from Geoffrey Hinton's homepage, including research interests and areas of focus from the content.\", \"memory\": \"Completed all steps: 1) Searched for 'Geoffrey Hinton'; 2) Reached Google Scholar and sorted by year; 3) Accessed homepage and summarized research interests from the content. The summary includes deep learning, neural networks, machine learning, AI, deep belief networks, representation learning, generative models, biologically plausible algorithms, t-SNE for visualization, interpretable AI, and recent advances such as diffusion models and Forward-Forward Algorithm. The task is fully accomplished.\", \"next_goal\": \"Finalize and report results, marking the task as successfully complete with full summary.\"}, \"action\": [{\"done\": {\"text\": \"Ultimate task complete: \\n\\n1. Searched for 'Geoffrey Hinton' and navigated to his Google Scholar page.\\n2. Sorted his publications by year as requested.\\n3. Navigated to his homepage and extracted/summarized his research interests as follows:\\n\\nGeoffrey Hinton's Research Interests:\\n- Deep Learning, Neural Networks, Machine Learning, and Artificial Intelligence.\\n- Co-invented Deep Belief Networks; developed fast learning algorithms for these networks.\\n- Explores biologically plausible alternatives to backpropagation (e.g., Forward-Forward Algorithm).\\n- Pioneer in representation learning via deep autoencoders and methods for reducing data dimensionality.\\n- Advanced generative models capable of generating/recognizing complex data (e.g., images, movies of generating digits).\\n- Developed neural additive models for interpretable machine learning.\\n- Extensive work in unsupervised/self-supervised learning with minimal supervision.\\n- Neuro-inspired computational mechanisms and investigation of backpropagation-like processes in biological neural systems.\\n- Data visualization and embeddings \\u2014 key developer of t-SNE visualization tool for high-dimensional data.\\n- Recent focuses: diffusion models, sequence interfaces for vision tasks, and panoptic segmentation for images/videos.\\n\\nMajor contributions include: Deep Belief Networks, Forward-Forward Algorithm, neural additive models, and t-SNE. His research has deeply impacted both foundational ML theory and practical applications, with a strong influence on academia and industry.\", \"success\": true}}]}}"}]
[{"role": "user", "content": "Your task is to extract the content of the page. You will be given a page and a goal and you should extract all relevant information around this goal from the page. If the goal is vague, summarize the page. Respond in json format. Extraction goal: Find and summarize Geoffrey Hinton's research interests from homepage content, including any stated areas, focus, or major contributions., Page: \nHome Page of Geoffrey Hinton\n\n\n\n|  |  |  |\n| --- | --- | --- |\n| |  | | --- | |  | | BIOGRAPHICAL INFORMATION | | ......Curriculum Vitae  [.pdf](shortcv.pdf) | | ......[Biographical sketch](bio.html) | | ......[Brief Bio](briefbio23.txt) | | ......[Photographs](geoffphotos.html) | |  | | PUBLICATIONS | | ......[Publications by year](papers.html) | | ......[Slides of public talks](talks.html) | |  | | MEDIA INTERVIEWS | | ....[CBS 60 Minutes, Sept 2023](https://www.youtube.com/watch?v=qrvK_KuIeJk) | | ....[Interview at Collision Conference, Toronto, June 2023](collision.mp4) | | ....[CNN Amanpour and Company, May 2023](https://www.youtube.com/watch?v=Y6Sgp7y178k&t=935s) | | ....[PBS, May 2023](https://www.youtube.com/watch?v=yAgQWnD31nE) | | ....[BBC News, May 2023](https://www.youtube.com/watch?v=DsBGaHywRhs) | | ....[CNN Jake Tapper, May 2023](https://www.youtube.com/watch?v=FAbsoxQtUwM&t=3s) | | ....[CBC The National, May 2023](https://www.youtube.com/watch?v=CkTUgOOa3n8&t=99s) | | ....[CBS Morning News, March 2023](https://www.youtube.com/watch?v=qpoRO378qRY&t=13s) | | ....[Interview on CBC radio \"The Current\", May 5 2015](http://www.cbc.ca/radio/thecurrent/the-current-for-may-5-2015-1.3061292) | |  | | VIDEO LECTURES | | ....[YouTube (Feb 2024) The Romanes Lecture (40mins)](https://www.youtube.com/watch?v=N1TEjTeQeg0&t=39s) | | ....[YouTube (Dec 2023) The Arthur Miller Lecture on Science and Ethics (1.13hr)](https://www.youtube.com/watch?v=iWPo7Yhg7Vc&t=121s) | | ....[YouTube (May 2023) Two Paths to Intlligence (1hr)](https://www.youtube.com/watch?v=rGgGOccMEiY&t=60s) | | ....[YouTube (2012) Brains, Sex and Machine Learning (1hr)](http://www.youtube.com/watch?v=DleXA5ADG78) | | ....[YouTube (2007) The Next Generation of Neural Networks (1hr)](http://www.youtube.com/watch?v=AyzOUbkUf3M) | | ....[YouTube (2010) Recent Developments in Deep Learning (1hr)](http://www.youtube.com/watch?v=VdIURAu1-aU) | |  | | TUTORIALS | | ....[Tutorial (2009) Deep Belief Nets (3hrs)](http://videolectures.net/jul09_hinton_deeplearn/) [ppt](ucltutorial.ppt) [pdf](ucltutorial.pdf) [readings](http://www.cs.toronto.edu/~hinton/deeprefs.html) | | ....[Workshop Talk (2007) How to do backpropagation in a brain (20mins)](http://www.cs.nyu.edu/~yann/deep07/videos/mov010.avi) [ppt2007](backpropincortex2007.ppt) [pdf2007](backpropincortex2007.pdf) [ppt2014](backpropincortex2014.ppt) [pdf2014](backpropincortex2014.pdf) | |  | | 2012 COURSERA COURSE LECTURES: Neural Networks for Machine Learning | |  | | ....[Lectures](coursera_lectures.html)(.mp4) | | ....[Lecture Slides](coursera_slides.html)(.pptx or .pdf)) | |  | | OLD UNIVERSITY OF TORONTO COURSES | |  | | ....[csc321 Spring 2013](http://www.cs.toronto.edu/~tijmen/csc321/)(undergrad) | | ....[csc2535 Spring 2013](csc2535/index.html)(graduate) | |  | | OLD TUTORIAL SLIDES | | ....[2011 NIPS workshop talk pdf](grenada.pdf) [ppt](grenada.ppt) ........[paper on Transforming Autoencoders](http://www.cs.toronto.edu/~hinton/absps/transauto6.pdf) | | ....[2007 NIPS tutorial html](nipstutorial/nipstut3.htm) [ppt](nipstutorial/nipstut3.ppt) [ps](nipstutorial/nipstut3.ps) [pdf](nipstutorial/nipstut3.pdf) ........[Readings: 2007 NIPS tutorial](http://www.cs.toronto.edu/~hinton/csc2515/deeprefs.html) | | ....[CIFAR Summer School 2007](http://www.cs.toronto.edu/~amnih/cifar/) | | ....[CIAR Summer School 2006](http://www.cs.toronto.edu/~vnair/ciar/) | | ....[CIFAR Summer School 2005](sstut.html) | | ....[List of Past Tutorials](nntut.html) | |  | |  | | MOVIES | | ....[generating digits](http://www.cs.toronto.edu/~hinton/digits.html) | | ....[speaking with a glove (Sidney Fels)](http://www.cs.toronto.edu/~hinton/glovetalk.mov) | |  | | MATLAB CODE | | ....[Matlab for Science paper](http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html) | | ....[t-SNE software](http://homepage.tudelft.nl/19j49/t-SNE.html) | | ....[trajectory from motor program](code/computetraj.m) | | ....[ink from trajectory](code/drawtraj.m) | | ....[introduction to python](python.jpg) | |  | | SUPERVISION | | ....[Current PhD and Master's Students](gradstucurrent.html) | | ....[Former PhD Students](gradstuphd.html) | | ....[Former Master's Students](gradstumasters.html) | | ....[PostDocs](postdocs.html) | |  | | MACHINE LEARNING AT TORONTO | | ....[learning.cs.toronto.edu](http://learning.cs.toronto.edu) | |  | | HOME PAGE (top level) | | ....[www.cs.toronto.edu/~hinton](http://www.cs.toronto.edu/~hinton) | |  | Geoffrey E. Hinton  | Department of Computer Science |  | **email**: geoffrey [dot] hinton [at] gmail [dot] com | | | | --- | --- | --- | --- | --- | | **[University of Toronto](http://www.toronto.edu/)** |  | **voice**: send email | | | | 6 King's College Rd. |  | **fax**: scan and send email | | Toronto, Ontario |  |  | |  |   **Information for prospective students, postdocs and visitors:** I will not be taking any more students, postdocs or visitors.  **Basic papers on deep learning**  LeCun, Y., Bengio, Y. and Hinton, G. E. (2015) Deep Learning Nature, Vol. 521, pp 436-444. [[pdf](absps/NatureDeepReview.pdf)]    Hinton, G. E., Osindero, S. and Teh, Y. (2006) A fast learning algorithm for deep belief nets. Neural Computation, **18**, pp 1527-1554. [[pdf](absps/ncfast.pdf)]  [Movies of the neural network generating and recognizing digits](http://www.cs.toronto.edu/~hinton/digits.html)  Hinton, G. E. and Salakhutdinov, R. R. (2006) Reducing the dimensionality of data with neural networks. Science, Vol. 313. no. 5786, pp. 504 - 507, 28 July 2006. [[full paper](absps/science.pdf) ] [[supporting online material (pdf)](http://www.cs.toronto.edu/~hinton/absps/science_som.pdf) ] [[Matlab code](http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html) ]  **Recent Papers**  Hinton, G. E. (2022) The Forward-Forward Algorithm: Some Preliminary Investigations arXiv:2212.13345  [[pdf of final version](absps/FFXfinal.pdf)] [[ffcode.zip matlab code for the supervised version of FF with the first 10 pixels being the labels](ffcode.zip)] [[load mnistdata.mat in matlab to create the data](mnistdata.mat)] [[README.txt explains what to do to run FF](README.txt)} Sindy Loewe's translation to python code is available at https://github.com/loeweX/Forward-Forward  Chen, T., Zhang, R., & Hinton, G. (2022) Analog bits: Generating discrete data using diffusion models with self-conditioning arXiv preprint arXiv:2208.04202 [[pdf](absps/analog.pdf)] Ren, M., Kornblith, S., Liao, R., & Hinton, G. (2022) Scaling Forward Gradient With Local Losses arXiv preprint arXiv:2210.03310 [[pdf](absps/forwardgradient.pdf)] Chen, T., Saxena, S., Li, L., Lin, T. Y., Fleet, D. J., & Hinton, G. (2022) A unified sequence interface for vision tasks arXiv preprint arXiv:2206.07669 [[pdf](absps/unifiedinterface.pdf)] Chen, T., Li, L., Saxena, S., Hinton, G., & Fleet, D. J.(2022)  A generalist framework for panoptic segmentation of images and videos arXiv preprint arXiv:2210.06366 [[pdf](absps/panoptic.pdf)] Liao, R., Kornblith, S., Ren, M., Fleet, D. J., & Hinton, G. (2022) Gaussian-Bernoulli RBMs Without Tears arXiv preprint arXiv:2210.10318 [[pdf](absps/GBRBM.pdf)] Culp, L., Sabour, S., & Hinton, G. E. (2022) Testing GLOM's ability to infer wholes from ambiguous parts arXiv preprint arXiv: 2211.16564 [[pdf](absps/glomculp.pdf)] Agarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B., Caruana, R., & Hinton, G. E. (2021) Neural additive models:Interpretable machine learning with neural nets Advances in Neural Information Processing Systems, 34, 4699-4711. [[pdf](absps/NAM.pdf)] Bengio, Y., Lecun, Y., & Hinton, G. (2021) Deep learning for AI  Communications of the ACM, 64(7), 58-65. [[pdf](absps/ACM21.pdf)]  [2021 commencement address at IIT Mumbai](HintonMumbai.pdf)  [Joseph Turian's map of 2500 English words produced by using t-SNE on the word feature vectors learned by Collobert & Weston, ICML 2008](turian.png)  [Doing analogies by using vector algebra on word embeddings (in 2008)](charniak.txt)  [My old favorite Gary Marcus quote](marcusquote.html)  [GPT-4 corrects Gary Marcus](GPT4correctsMarcus.txt)    My new favorite Gary Marcus quote  \"It gloms on to different clusters of text. That is all.\"  [A new concept of healing from the people who design unimprovised explosive devices](minefield.pdf) |\n\n\n\n"}, {"role": "assistant", "content": "```json\n{\n  \"person\": \"Geoffrey Hinton\",\n  \"extraction_goal\": \"Summarize Geoffrey Hinton's research interests, including any stated areas, focus, or major contributions.\",\n  \"research_interests\": [\n    \"Deep Learning\",\n    \"Neural Networks\",\n    \"Machine Learning\",\n    \"Artificial Intelligence\"\n  ],\n  \"focus_areas_and_themes\": [\n    {\n      \"area\": \"Deep Belief Networks\",\n      \"details\": \"Co-invented Deep Belief Nets; Developed fast learning algorithms for these networks.\"\n    },\n    {\n      \"area\": \"Backpropagation and Learning Algorithms\",\n      \"details\": \"Exploration of biologically plausible alternatives to backpropagation in neural networks (e.g., Forward-Forward Algorithm).\"\n    },\n    {\n      \"area\": \"Representation Learning\",\n      \"details\": \"Work on methods for reducing the dimensionality of data using neural networks (e.g., deep autoencoders).\"\n    },\n    {\n      \"area\": \"Generative Models\",\n      \"details\": \"Development of neural network models capable of generating and recognizing complex data such as images (e.g., movies of generating digits).\"\n    },\n    {\n      \"area\": \"Interpretable Machine Learning\",\n      \"details\": \"Development of neural additive models for interpretable machine learning with neural networks.\"\n    },\n    {\n      \"area\": \"Unsupervised and Self-supervised Learning\",\n      \"details\": \"Work on algorithms where learning can occur with minimal supervision, as in Deep Belief Nets and other recent approaches.\"\n    },\n    {\n      \"area\": \"Neuro-inspired Computation\",\n      \"details\": \"Investigation of mechanisms inspired by the brain, including how backpropagation-like processes might be realized in biological neural systems.\"\n    },\n    {\n      \"area\": \"Data Visualization and Embeddings\",\n      \"details\": \"Development and use of t-SNE for visualizing high-dimensional data (e.g., word vectors).\"\n    },\n    {\n      \"area\": \"Diffusion Models & Discrete Data Generation\",\n      \"details\": \"Recent work on generating discrete data using diffusion models with self-conditioning.\"\n    },\n    {\n      \"area\": \"Vision and Sequence Interfaces\",\n      \"details\": \"Unified sequence interface for vision tasks; panoptic segmentation of images and videos.\"\n    }\n  ],\n  \"major_contributions\": [\n    {\n      \"title\": \"Deep Belief Networks\",\n      \"citation\": \"Hinton, G. E., Osindero, S. and Teh, Y. (2006) A fast learning algorithm for deep belief nets. Neural Computation, 18, pp 1527-1554.\"\n    },\n    {\n      \"title\": \"Dimensionality Reduction with Neural Networks\",\n      \"citation\": \"Hinton, G. E. and Salakhutdinov, R. R. (2006) Reducing the dimensionality of data with neural networks. Science, Vol. 313. no. 5786, pp. 504 - 507.\"\n    },\n    {\n      \"title\": \"Foundational Review of Deep Learning\",\n      \"citation\": \"LeCun, Y., Bengio, Y. and Hinton, G. E. (2015) Deep Learning. Nature, Vol. 521, pp 436-444.\"\n    },\n    {\n      \"title\": \"Forward-Forward Algorithm\",\n      \"citation\": \"Hinton, G. E. (2022) The Forward-Forward Algorithm: Some Preliminary Investigations arXiv:2212.13345.\"\n    },\n    {\n      \"title\": \"Interpretable Neural Additive Models\",\n      \"citation\": \"Agarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B., Caruana, R., & Hinton, G. E. (2021) Neural additive models: Interpretable machine learning with neural nets. NeurIPS.\"\n    },\n    {\n      \"title\": \"t-SNE Data Visualization\",\n      \"citation\": \"Software and applications for visualizing high-dimensional data, notably for word embeddings.\"\n    }\n  ],\n  \"teaching_and_impact\": [\n    \"Produced extensive tutorials and lecture series on deep learning, neural networks, and related topics (e.g., Coursera, NIPS, CIFAR Summer Schools).\",\n    \"Mentored and supervised many prominent researchers and students in AI.\",\n    \"Has contributed both foundational algorithms and practical software tools utilized widely in machine learning community.\"\n  ],\n  \"recent_topics\": [\n    \"Forward-Forward Algorithm\",\n    \"Diffusion models with self-conditioning\",\n    \"Scaling forward gradient with local losses\",\n    \"Unified sequence interfaces for vision tasks\",\n    \"Panoptic segmentation of images and videos\",\n    \"Gaussian-Bernoulli Restricted Boltzmann Machines\"\n  ],\n  \"summary\": \"Geoffrey Hinton is a pioneering researcher in the field of machine learning and artificial intelligence, with major contributions to deep learning, neural networks, representation learning, and biologically plausible learning algorithms. His work spans foundational theoretical algorithms, innovative practical models (such as Deep Belief Nets and deep autoencoders), interpretable AI, and data visualization. He continues to explore new learning paradigms including the Forward-Forward algorithm, and his research has had broad impact on both academia and industry.\"\n}\n```"}]
[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for geoffrey hinton, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "2"}, {"role": "user", "content": "Action result: \ud83d\udd0d  Searched for \"Geoffrey Hinton\" in Google"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "3"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 32: Geoffrey Hinton"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "4"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 62: Year"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "5"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 55: Homepage"}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: https://www.cs.toronto.edu/~hinton/\nAvailable tabs:\n[TabInfo(page_id=0, url='https://www.cs.toronto.edu/~hinton/', title='Home Page of Geoffrey Hinton')]\nInteractive elements from top layer of the current page inside the viewport:\n[Start of page]\nBIOGRAPHICAL INFORMATION\n......Curriculum Vitae\n[0]<a .pdf/>\n......\n[1]<a Biographical sketch/>\n......\n[2]<a Brief Bio/>\n......\n[3]<a Photographs/>\nPUBLICATIONS\n......\n[4]<a Publications by year/>\n......\n[5]<a Slides of public talks/>\nMEDIA INTERVIEWS\n....\n[6]<a CBS 60 Minutes, Sept 2023/>\n....\n[7]<a Interview at Collision Conference, Toronto, June 2023/>\n....\n[8]<a CNN Amanpour and Company, May 2023/>\n....\n[9]<a PBS, May 2023/>\n....\n[10]<a BBC News, May 2023/>\n....\n[11]<a CNN Jake Tapper, May 2023/>\n....\n[12]<a CBC The National, May 2023/>\n....\n[13]<a CBS Morning News, March 2023/>\n....\n[14]<a Interview on CBC radio \"The Current\", May 5 2015/>\nVIDEO LECTURES\n....\n[15]<a YouTube (Feb 2024)\nThe Romanes Lecture (40mins)/>\n....\n[16]<a YouTube (Dec\n2023)\nThe Arthur Miller Lecture on Science and Ethics (1.13hr)/>\n....\n[17]<a YouTube (May 2023)\nTwo Paths to Intlligence (1hr)/>\n....\n[18]<a YouTube (2012)\nBrains, Sex and Machine Learning (1hr)/>\n....\n[19]<a YouTube (2007)\nThe Next Generation of Neural Networks (1hr)/>\n....\n[20]<a YouTube (2010)\nRecent Developments in Deep Learning (1hr)/>\nTUTORIALS\n....\n[21]<a Tutorial (2009)\nDeep Belief Nets (3hrs)/>\n[22]<a ppt/>\n[23]<a pdf/>\n[24]<a readings/>\n....\n[25]<a Workshop Talk (2007)\nHow to do backpropagation in a brain (20mins)/>\n[26]<a ppt2007/>\n[27]<a pdf2007/>\n[28]<a ppt2014/>\n[29]<a pdf2014/>\n2012 COURSERA COURSE LECTURES:\nNeural Networks for Machine Learning\n....\n[30]<a Lectures/>\n(.mp4)\n....\n[31]<a Lecture Slides/>\n(.pptx or .pdf))\nOLD UNIVERSITY OF TORONTO COURSES\n....\n[32]<a csc321 Spring\n2013/>\n(undergrad)\n....\n[33]<a csc2535 Spring 2013/>\n(graduate)\nOLD TUTORIAL SLIDES\n....\n[34]<a 2011 NIPS workshop talk pdf/>\n[35]<a ppt/>\n........\n[36]<a paper\non Transforming Autoencoders/>\n....\n[37]<a 2007 NIPS tutorial html/>\n[38]<a ppt/>\n[39]<a ps/>\n[40]<a pdf/>\n........\n[41]<a Readings:\n2007 NIPS tutorial/>\n....\n[42]<a CIFAR Summer School 2007/>\n....\n[43]<a CIAR Summer School 2006/>\n....\n[44]<a CIFAR Summer School 2005/>\n....\n[45]<a List of Past Tutorials/>\nMOVIES\n....\n[46]<a generating digits/>\n....\n[47]<a speaking\nwith a glove (Sidney Fels)/>\nMATLAB CODE\n....\n[48]<a Matlab for Science paper/>\n....\n[49]<a t-SNE software/>\n....\n[50]<a trajectory from motor program/>\n....\n[51]<a ink from trajectory/>\n....\n[52]<a introduction to python/>\nSUPERVISION\n....\n[53]<a Current PhD and Master's Students/>\n....\n[54]<a Former PhD Students/>\n....\n[55]<a Former Master's Students/>\n....\n[56]<a PostDocs/>\nMACHINE LEARNING AT TORONTO\n....\n[57]<a learning.cs.toronto.edu/>\nHOME PAGE (top level)\n....\n[58]<a www.cs.toronto.edu/~hinton/>\nGeoffrey E. Hinton\nDepartment of Computer Science\nemail\n: geoffrey [dot] hinton [at]\ngmail [dot] com\n[59]<a University of Toronto/>\nvoice\n: send email\n6 King's College Rd.\nfax\n: scan and send email\nToronto, Ontario\nInformation for prospective students, postdocs and visitors:\nI will not be taking any more students, postdocs or visitors.\nBasic papers on deep learning\nLeCun, Y., Bengio, Y. and Hinton, G. E. (2015)\nDeep Learning\nNature, Vol. 521, pp 436-444.\n[\n[60]<a pdf/>\n]\nHinton, G. E., Osindero, S. and Teh, Y. (2006)\nA fast learning algorithm for deep belief nets.\nNeural Computation,\n18\n, pp 1527-1554. \n[\n[61]<a pdf/>\n]\n[62]<a Movies of the neural network generating and recognizing digits/>\nHinton, G. E. and Salakhutdinov, R. R. (2006)\nReducing the dimensionality of data with neural networks.\nScience, Vol. 313. no. 5786, pp. 504 - 507, 28 July 2006.\n[\n[63]<a full paper/>\n]\n[\n[64]<a supporting online material (pdf)/>\n]\n[\n[65]<a Matlab code/>\n]\nRecent Papers\nHinton, G. E. (2022)\nThe Forward-Forward Algorithm: Some Preliminary\nInvestigations\narXiv:2212.13345\n[\n[66]<a pdf of final version/>\n]\n[\n[67]<a ffcode.zip matlab code for the supervised version of FF\nwith the first 10 pixels being the labels/>\n]\n[\n[68]<a load mnistdata.mat in matlab to create the data/>\n]\n[\n[69]<a README.txt explains what to do to run\nFF/>\n}\nSindy Loewe's translation to python code is available at\nhttps://github.com/loeweX/Forward-Forward\nChen, T., Zhang, R., & Hinton, G. (2022)\nAnalog bits: Generating discrete data using diffusion models with\nself-conditioning\narXiv preprint arXiv:2208.04202\n[\n[70]<a pdf/>\n]\nRen, M., Kornblith, S., Liao, R., & Hinton, G. (2022)\nScaling Forward Gradient With Local Losses\narXiv preprint arXiv:2210.03310\n[\n[71]<a pdf/>\n]\nChen, T., Saxena, S., Li, L., Lin, T. Y., Fleet, D. J., & Hinton, G. (2022)\nA unified sequence interface for vision tasks\narXiv preprint arXiv:2206.07669\n[\n[72]<a pdf/>\n]\nChen, T., Li, L., Saxena, S., Hinton, G., & Fleet, D. J.(2022)\nA generalist framework for panoptic segmentation of images and\nvideos\narXiv preprint arXiv:2210.06366\n[\n[73]<a pdf/>\n]\nLiao, R., Kornblith, S., Ren, M., Fleet, D. J., & Hinton, G. (2022)\nGaussian-Bernoulli RBMs Without Tears\narXiv preprint arXiv:2210.10318\n[\n[74]<a pdf/>\n]\nCulp, L., Sabour, S., & Hinton, G. E. (2022)\nTesting GLOM's ability to infer wholes from ambiguous parts\narXiv preprint arXiv: 2211.16564\n[\n[75]<a pdf/>\n]\nAgarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B.,\nCaruana, R., & Hinton, G. E. (2021)\nNeural additive models:Interpretable machine learning with neural nets\nAdvances in Neural Information Processing Systems, 34, 4699-4711.\n[\n[76]<a pdf/>\n]\nBengio, Y., Lecun, Y., & Hinton, G. (2021)\nDeep learning for AI\nCommunications of the ACM, 64(7), 58-65.\n[\n[77]<a pdf/>\n]\n[78]<a 2021 commencement address at IIT Mumbai/>\n[79]<a Joseph Turian's map of 2500 English words produced by using t-SNE on\n the word feature vectors learned by Collobert & Weston, ICML 2008/>\n[80]<a Doing analogies by using vector algebra on word embeddings (in 2008)/>\n[81]<a My old favorite Gary Marcus quote/>\n[82]<a GPT-4 corrects Gary Marcus/>\nMy new favorite Gary Marcus quote\n\"It gloms on to different clusters of text. That is all.\"\n[83]<a A new concept of healing from the people who design unimprovised\n   explosive devices/>\n... 511 pixels below - scroll or extract content to see more ...\nCurrent step: 5/100Current date and time: 2025-04-18 20:19\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - Navigated to Geoffrey Hinton's homepage. The homepage loaded as intended. The goal now is to extract his research interests for summary.\", \"memory\": \"Searched for 'Geoffrey Hinton', opened his Google Scholar and sorted by year, navigated to his homepage. 3 out of 4 major goals completed. The final step is to summarize Hinton's research interests by extracting relevant information from his homepage. No explicit 'Research Interests' section is immediately visible in the viewport, so further inspection or extraction of page content is needed.\", \"next_goal\": \"Extract page content to find and summarize Geoffrey Hinton's research interests from his homepage.\"}, \"action\": [{\"extract_content\": {\"goal\": \"Find and summarize Geoffrey Hinton's research interests from homepage content, including any stated areas, focus, or major contributions.\"}}]}}"}]
[{"role": "system", "content": "You are an AI agent designed to automate browser tasks. Your goal is to accomplish the ultimate task following the rules.\n\n# Input Format\nTask\nPrevious steps\nCurrent URL\nOpen Tabs\nInteractive Elements\n[index]<type>text</type>\n- index: Numeric identifier for interaction\n- type: HTML element type (button, input, etc.)\n- text: Element description\nExample:\n[33]<button>Submit Form</button>\n\n- Only elements with numeric indexes in [] are interactive\n- elements without [] provide only context\n\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{\"current_state\": {\"evaluation_previous_goal\": \"Success|Failed|Unknown - Analyze the current elements and the image to check if the previous goals/actions are successful like intended by the task. Mention if something unexpected happened. Shortly state why/why not\",\n\"memory\": \"Description of what has been done and what you need to remember. Be very specific. Count here ALWAYS how many times you have done something and how many remain. E.g. 0 out of 10 websites analyzed. Continue with abc and xyz\",\n\"next_goal\": \"What needs to be done with the next immediate action\"},\n\"action\":[{\"one_action_name\": {// action-specific parameter}}, // ... more actions in sequence]}\n\n2. ACTIONS: You can specify multiple actions in the list to be executed in sequence. But always specify only one action name per item. Use maximum {max_actions} actions per sequence.\nCommon action sequences:\n- Form filling: [{\"input_text\": {\"index\": 1, \"text\": \"username\"}}, {\"input_text\": {\"index\": 2, \"text\": \"password\"}}, {\"click_element\": {\"index\": 3}}]\n- Navigation and extraction: [{\"go_to_url\": {\"url\": \"https://example.com\"}}, {\"extract_content\": {\"goal\": \"extract the names\"}}]\n- Actions are executed in the given order\n- If the page changes after an action, the sequence is interrupted and you get the new state.\n- Only provide the action sequence until an action which changes the page state significantly.\n- Try to be efficient, e.g. fill forms at once, or chain actions where nothing changes on the page\n- only use multiple actions if it makes sense.\n\n3. ELEMENT INTERACTION:\n- Only use indexes of the interactive elements\n- Elements marked with \"[]Non-interactive text\" are non-interactive\n\n4. NAVIGATION & ERROR HANDLING:\n- If no suitable elements exist, use other functions to complete the task\n- If stuck, try alternative approaches - like going back to a previous page, new search, new tab etc.\n- Handle popups/cookies by accepting or closing them\n- Use scroll to find elements you are looking for\n- If you want to research something, open a new tab instead of using the current tab\n- If captcha pops up, try to solve it - else try a different approach\n- If the page is not fully loaded, use wait action\n\n5. TASK COMPLETION:\n- Use the done action as the last action as soon as the ultimate task is complete\n- Dont use \"done\" before you are done with everything the user asked you, except you reach the last step of max_steps. \n- If you reach your last step, use the done action even if the task is not fully finished. Provide all the information you have gathered so far. If the ultimate task is completly finished set success to true. If not everything the user asked for is completed set success in done to false!\n- If you have to do something repeatedly for example the task says for \"each\", or \"for all\", or \"x times\", count always inside \"memory\" how many times you have done it and how many remain. Don't stop until you have completed like the task asked you. Only call done after the last step.\n- Don't hallucinate actions\n- Make sure you include everything you found out for the ultimate task in the done text parameter. Do not just say you are done, but include the requested information of the task. \n\n6. VISUAL CONTEXT:\n- When an image is provided, use it to understand the page layout\n- Bounding boxes with labels on their top right corner correspond to element indexes\n\n7. Form filling:\n- If you fill an input field and your action sequence is interrupted, most often something changed e.g. suggestions popped up under the field.\n\n8. Long tasks:\n- Keep track of the status and subresults in the memory. \n\n9. Extraction:\n- If your task is to find information - call extract_content on the specific pages to get and store the information.\nYour responses must be always JSON with the specified format. "}, {"role": "user", "content": "Your ultimate task is: \"\"\"open browser, search for geoffrey hinton, navigate to their google scholar page and sort the publications by year. Then, go to their homepage if available and summarize their research interests.\"\"\". If you achieved your ultimate task, stop everything and use the done action in the next step to complete the task. If not, continue as usual."}, {"role": "user", "content": "Example output:"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "Browser started", "tool_call_id": "1"}, {"role": "user", "content": "[Your task history memory starts here]"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "2"}, {"role": "user", "content": "Action result: \ud83d\udd0d  Searched for \"Geoffrey Hinton\" in Google"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "3"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 32: Geoffrey Hinton"}, {"role": "assistant", "content": ""}, {"role": "tool", "content": "", "tool_call_id": "4"}, {"role": "user", "content": "Action result: \ud83d\uddb1\ufe0f  Clicked button with index 62: Year"}, {"role": "user", "content": "\n[Task history memory ends]\n[Current state starts here]\nThe following is one-time information - if you need to remember it write it to memory:\nCurrent url: https://scholar.google.com/citations?hl=en&user=JicYPdAAAAAJ&view_op=list_works&sortby=pubdate\nAvailable tabs:\n[TabInfo(page_id=0, url='https://scholar.google.com/citations?hl=en&user=JicYPdAAAAAJ&view_op=list_works&sortby=pubdate', title='\\u202aGeoffrey Hinton\\u202c - \\u202aGoogle Scholar\\u202c')]\nInteractive elements from top layer of the current page inside the viewport:\n[Start of page]\n[0]<div Loading...\nThe system can't perform the operation now. Try again later.\nCitations per year\nDuplicate citations\nThe following articles are merged in Scholar. Their\ncombined citations\nare counted only for the first article.\nMerged citations\nThis \"Cited by\" count includes citations to the following articles in Scholar. The ones marked\n*\nmay be different from the article in the profile.\nAdd co-authors\nCo-authors\nFollow\nNew articles by this author\nNew citations to this author\nNew articles related to this author's research\nEmail address for updates\nDone\nMy profile\nMy library\nMetrics\nAlerts\nSettings\nSign in\nCited by\nAll\nSince 2020\n920412\n544571\n189\n132\n494\n366\n0\n110000\n55000\n27500\n82500\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025\n2513\n3516\n3724\n4006\n4479\n4375\n3893\n3812\n3643\n3625\n3452\n3188\n3296\n3702\n3692\n3372\n3821\n4176\n4586\n4343\n4768\n5237\n5722\n6836\n10068\n12877\n19082\n30094\n43869\nPublic access\nView all\n9 articles\n1 article\navailable\nnot available\nBased on funding mandates\nCo-authors\nGeoffrey Hinton\nEmeritus Prof. Computer Science,\nVerified email at cs.toronto.edu -\nArticles\nCited by\nPublic access\nCo-authors\nSort\nSort by citations\nSort by year\nSort by title\nCited by\nYear\nT Chen, S Komblith, M Norouzi, GE Hinton, KJ Swersky\nUS Patent 12,254,413\n, 2025\n2025\nT Chen, S Komblith, M Norouzi, GE Hinton, KJ Swersky\nUS Patent App. 18/960,623\n, 2025\n2025\nW Chan, C Saharia, GE Hinton, M Norouzi, N Jaitly\nUS Patent 12,242,818\n, 2025\n2025\nT Chen, R Zhang, GE Hinton\nUS Patent App. 18/366,638\n, 2025\n2025\nY Bengio, S Mindermann, D Privitera, T Besiroglu, R Bommasani, ...\narXiv preprint arXiv:2501.17805\n, 2025\n2025\nA Krizhevsky, I Sutskever, GE Hinton\nUS Patent App. 18/438,368\n, 2024\n2024\nAR Kosiorek, GE Hinton, SSR Aghdam, YW Teh\nUS Patent 12,067,758\n, 2024\n2024\nY Bengio, G Hinton, A Yao, D Song, P Abbeel, T Darrell, YN Harari, ...\nScience 384 (6698), 842-845\n, 2024\n2024\nB Deng, K Genova, S Yazdani, S Bouaziz, GE Hinton, A Tagliasacchi\nUS Patent 11,978,268\n, 2024\n2024\nO Vinyals, JA Dean, GE Hinton\nUS Patent App. 18/399,358\n, 2024\n2024\nGE Hinton, NMW Frosst, NGR Papernot\nUS Patent 11,941,867\n, 2024\n2024\nA Krizhevsky, I Sutskever, GE Hinton\nUS Patent 11,928,577\n, 2024\n2024\nO Vinyals, JA Dean, GE Hinton\nUS Patent 11,900,232\n, 2024\n2024\nG Hinton\nRomanes Lecture, Oxford, UK 19\n, 2024\n2024\nT Chen, GE Hinton, S Kornblith, M Norouzi\nUS Patent 11,847,571\n, 2023\n2023\nGE Hinton, A Krizhevsky, I Sutskever, N Srivastava\nUS Patent 11,829,882\n, 2023\n2023\nY Bengio, G Hinton, A Yao, D Song, P Abbeel, YN Harari, YQ Zhang, ...\narXiv preprint arXiv:2310.17688, 18\n, 2023\n2023\nGE Hinton, NMW Frosst, SSR Aghdam\nUS Patent 11,694,060\n, 2023\n2023\nS Azizi, L Culp, J Freyberg, B Mustafa, S Baur, S Kornblith, T Chen, ...\nNature Biomedical Engineering 7 (6), 756-779\n, 2023\n2023\nThe system can't perform the operation now. Try again later./>\n[1]<a button/>\n[2]<a Homepage/>\n[3]<a Search;button/>\n[4]<a Sign in/>\n[5]<a Get my own profile/>\n[6]<button View all/>\n[7]<a This is the number of citations to all publications. The second column has the \"recent\" version of this metric which is the number of new citations in the last 5 years to all publications.>Citations/>\n[8]<a h-index is the largest number h such that h publications have at least h citations. The second column has the \"recent\" version of this metric which is the largest number h such that h publications have at least h new citations in the last 5 years.>h-index/>\n[9]<a i10-index is the number of publications with at least 10 citations. The second column has the \"recent\" version of this metric which is the number of publications that have received at least 10 new citations in the last 5 years.>i10-index/>\n[10]<a 63919/>\n[11]<a 81322/>\n[12]<a 90746/>\n[13]<a 102291/>\n[14]<a 104601/>\n[15]<a 107804/>\n[16]<a 109119/>\n[17]<a 29948/>\n[18]<a View all/>\n[19]<div Google Inc.\nVerified email at google.com/>\n[20]<img />\n[21]<a George E. Dahl/>\n[22]<div Francis Crick Professor, Salk Institute, Distingished Professor, UC San Diego\nVerified email at salk.edu/>\n[23]<img />\n[24]<a Terrence Sejnowski/>\n[25]<div Research Scientist, DeepMind\nVerified email at google.com/>\n[26]<img />\n[27]<a Vinod Nair/>\n[28]<div Research scientist, Facebook AI Research\nVerified email at fb.com/>\n[29]<img />\n[30]<a Abdelrahman Mohamed/>\n[31]<div U Toronto *** GOOGLE SCHOLAR CAN GIVE WRONG PUBLICATION DATE/REFERENCE - LOOK AT ACTUAL PAPER/BOOK!\nVerified email at utstat.toronto.edu/>\n[32]<img />\n[33]<a Radford Neal/>\n[34]<div Professor of Electrical and Computer Engineering, University of British Columbia\nVerified email at ece.ubc.ca/>\n[35]<img />\n[36]<a Sidney Fels/>\n[37]<div Professor of Psychology, Carnegie Mellon University\nVerified email at cmu.edu/>\n[38]<img />\n[39]<a David C. Plaut/>\n[40]<div Professor of Machine Learning, University of Edinburgh\nVerified email at inf.ed.ac.uk/>\n[41]<img />\n[42]<a Chris Williams/>\n[43]<div Distinguished Professor & Chancellor's Professor of Computer Science, UCLA\nVerified email at cs.ucla.edu/>\n[44]<img />\n[45]<a Demetri Terzopoulos/>\n[46]<div Professor of Biomedical Data Sciences, and  of  Statistics, Stanford University\nVerified email at stanford.edu/>\n[47]<img />\n[48]<a Robert Tibshirani/>\n[49]<div University of Texas at Dallas\nVerified email at utdallas.edu/>\n[50]<img />\n[51]<a Steven L. Small/>\n[52]<a button>Follow/>\n[53]<img />\n[54]<a University of Toronto/>\n[55]<a Homepage/>\n[56]<a machine learning/>\n[57]<a psychology/>\n[58]<a artificial intelligence/>\n[59]<a cognitive science/>\n[60]<a computer science/>\n[61]<a Title/>\n[62]<a Cited by/>\n[63]<a Systems and methods for contrastive learning of visual representations/>\n[64]<a Systems and Methods for Contrastive Learning of Visual Representations/>\n[65]<a Sequence modeling using imputation/>\n[66]<a GENERATING DISCRETE DATA USING DIFFUSION NEURAL NETWORKS/>\n[67]<a International AI Safety Report/>\n[68]<a 17/>\n[69]<a System and method for parallelizing convolutional neural networks/>\n[70]<a Object discovery in images through categorizing object parts/>\n[71]<a Managing extreme AI risks amid rapid progress/>\n[72]<a 226/>\n[73]<a Convex representation of objects using neural network/>\n[74]<a Training distilled machine learning models/>\n[75]<a Neural network training using the soft nearest neighbor loss/>\n[76]<a System and method for parallelizing convolutional neural networks/>\n[77]<a 1/>\n[78]<a Training distilled machine learning models/>\n[79]<a Will digital intelligence replace biological intelligence/>\n[80]<a 12/>\n[81]<a Systems and methods for contrastive learning of visual representations/>\n[82]<a 1/>\n[83]<a System and method for addressing overfitting in a neural network/>\n[84]<a Managing ai risks in an era of rapid progress/>\n[85]<a 104/>\n[86]<a Capsule neural networks/>\n[87]<a Robust and data-efficient generalization of self-supervised machine learning for diagnostic imaging/>\n[88]<a 180/>\n... 730 pixels below - scroll or extract content to see more ...\nCurrent step: 4/100Current date and time: 2025-04-18 20:19\n"}, {"role": "tool", "content": {"type": "function", "function": {"name": "AgentOutput", "description": "AgentOutput model with custom actions", "parameters": {"properties": {"current_state": {"description": "Current state of the agent", "properties": {"evaluation_previous_goal": {"type": "string"}, "memory": {"type": "string"}, "next_goal": {"type": "string"}}, "required": ["evaluation_previous_goal", "memory", "next_goal"], "type": "object"}, "action": {"description": "List of actions to execute", "items": {"properties": {"done": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}, "success": {"title": "Success", "type": "boolean"}}, "required": ["text", "success"], "title": "DoneAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Complete task - with return text and if the task is finished (success=True) or not yet  completly finished (success=False), because last step is reached"}, "search_google": {"anyOf": [{"properties": {"query": {"title": "Query", "type": "string"}}, "required": ["query"], "title": "SearchGoogleAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Search the query in Google in the current tab, the query should be a search query like humans search in Google, concrete and not vague or super long. More the single most important items. "}, "go_to_url": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "GoToUrlAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Navigate to URL in the current tab"}, "go_back": {"anyOf": [{"additionalProperties": true, "description": "Accepts absolutely anything in the incoming data\nand discards it, so the final parsed model is empty.", "properties": {}, "title": "NoParamsAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Go back"}, "wait": {"anyOf": [{"properties": {"seconds": {"default": 3, "title": "Seconds", "type": "integer"}}, "title": "wait_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Wait for x seconds default 3"}, "click_element": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index"], "title": "ClickElementAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Click element"}, "input_text": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}, "xpath": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Xpath"}}, "required": ["index", "text"], "title": "InputTextAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Input text into a input interactive element"}, "switch_tab": {"anyOf": [{"properties": {"page_id": {"title": "Page Id", "type": "integer"}}, "required": ["page_id"], "title": "SwitchTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Switch tab"}, "open_tab": {"anyOf": [{"properties": {"url": {"title": "Url", "type": "string"}}, "required": ["url"], "title": "OpenTabAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Open url in new tab"}, "extract_content": {"anyOf": [{"properties": {"goal": {"title": "Goal", "type": "string"}}, "required": ["goal"], "title": "extract_content_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Extract page content to retrieve specific information from the page, e.g. all company names, a specifc description, all information about, links with companies in structured format or simply links"}, "scroll_down": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll down the page by pixel amount - if no amount is specified, scroll down one page"}, "scroll_up": {"anyOf": [{"properties": {"amount": {"anyOf": [{"type": "integer"}, {"type": "null"}], "default": null, "title": "Amount"}}, "title": "ScrollAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Scroll up the page by pixel amount - if no amount is specified, scroll up one page"}, "send_keys": {"anyOf": [{"properties": {"keys": {"title": "Keys", "type": "string"}}, "required": ["keys"], "title": "SendKeysAction", "type": "object"}, {"type": "null"}], "default": null, "description": "Send strings of special keys like Escape,Backspace, Insert, PageDown, Delete, Enter, Shortcuts such as `Control+o`, `Control+Shift+T` are supported as well. This gets used in keyboard.press. "}, "scroll_to_text": {"anyOf": [{"properties": {"text": {"title": "Text", "type": "string"}}, "required": ["text"], "title": "scroll_to_text_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "If you dont find something which you want to interact with, scroll to it"}, "get_dropdown_options": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}}, "required": ["index"], "title": "get_dropdown_options_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Get all options from a native dropdown"}, "select_dropdown_option": {"anyOf": [{"properties": {"index": {"title": "Index", "type": "integer"}, "text": {"title": "Text", "type": "string"}}, "required": ["index", "text"], "title": "select_dropdown_option_parameters", "type": "object"}, {"type": "null"}], "default": null, "description": "Select dropdown option for interactive element index by the text of the option you want to select"}}, "type": "object"}, "min_items": 1, "type": "array"}}, "required": ["current_state", "action"], "type": "object"}}}}, {"role": "assistant", "content": "{\"name\": \"AgentOutput\", \"parameters\": {\"current_state\": {\"evaluation_previous_goal\": \"Success - Publications are now sorted by year on Geoffrey Hinton's Google Scholar page as intended. Homepage link is visible and accessible for the next step.\", \"memory\": \"Searched for 'Geoffrey Hinton', opened his Google Scholar profile, and sorted publications by year. 3 out of 4 main goals are complete. The Homepage link is index 55. Next, visit the homepage to summarize research interests.\", \"next_goal\": \"Go to Geoffrey Hinton's homepage from his Google Scholar profile.\"}, \"action\": [{\"click_element\": {\"index\": 55}}]}}"}]
